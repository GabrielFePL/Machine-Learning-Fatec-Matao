# Relat√≥rio de Conclus√£o ‚Äì Avalia√ß√£o Pr√°tica  
## An√°lise Econ√¥mica e Criptofinanceira com Alpha Vantage (C√¢mbio e Bitcoin)

Este relat√≥rio apresenta a conclus√£o da avalia√ß√£o pr√°tica da disciplina, que consistiu na an√°lise econ√¥mica e criptofinanceira utilizando a API Alpha Vantage. O foco foi a coleta, tratamento e an√°lise de dados relacionados ao c√¢mbio e ao Bitcoin, com a implementa√ß√£o de scripts em Python.

Ao longo do documento, s√£o detaladas as justificativas para as escolhas t√©cnicas realizadas, como bibliotecas utilizadas, estrat√©gias de manipula√ß√£o de dados e formas de visualiza√ß√£o dos resultados. Tamb√©m s√£o discutidos os crit√©rios adotados para garantir a precis√£o, reprodutibilidade e relev√¢ncia das an√°lises desenvolvidas.

O objetivo principal √© demonstrar a aplica√ß√£o pr√°tica dos conhecimentos adquiridos, integrando fundamentos de economia, criptoativos e programa√ß√£o para extrair insights relevantes a partir de dados financeiros.

## Introdu√ß√£o Geral das Escolhas e Implementa√ß√µes

A abordagem adotada na avalia√ß√£o foi dividida em duas grandes etapas principais: **pr√©-processamento de dados** e **ingest√£o bayesiana de dados**. Essa separa√ß√£o teve como objetivo estruturar melhor o fluxo de trabalho e garantir uma an√°lise robusta e confi√°vel dos dados obtidos pela API Alpha Vantage.

### 1. Pr√©-processamento de Dados

O pr√©-processamento foi uma etapa fundamental para garantir a qualidade dos dados utilizados nas an√°lises. Essa fase incluiu:

- **Coleta automatizada de dados** de c√¢mbio e Bitcoin por meio da API Alpha Vantage.
- **Tratamento de dados ausentes e inconsistentes**, como valores nulos justificadas por eventos de mercado ou an√°lises personalizadas inseridas.
- **Convers√£o de formatos de data e hora**, padronizando a granularidade temporal para facilitar an√°lises agregadas.
- **Normaliza√ß√£o de escalas** para compara√ß√£o entre s√©ries temporais heterog√™neas (por exemplo, c√¢mbio USD/BRL e pre√ßos de BTC/USD).
- **Cria√ß√£o de vari√°veis auxiliares**, como m√©dias m√≥veis, volatilidade e retornos logar√≠tmicos, com o intuito de enriquecer a base anal√≠tica.

Essa etapa permitiu transformar os dados brutos em uma estrutura coerente e adequada para modelagens posteriores.

### 2. Ingest√£o Bayesiana de Dados

A segunda etapa consistiu na aplica√ß√£o de uma abordagem **classificat√≥ria baseada no Teorema de Bayes**, utilizando o modelo **Naive Bayes Gaussiano (GaussianNB)** da biblioteca `scikit-learn`. Apesar do nome "ingest√£o neural" ter sido inicialmente mencionado, a implementa√ß√£o n√£o se baseia em redes neurais artificiais, mas sim em um classificador estat√≠stico probabil√≠stico.

As justificativas para o uso dessa abordagem s√£o:

- O **Naive Bayes** √© eficiente para conjuntos de dados com m√∫ltiplas classes e apresenta √≥timo desempenho em classifica√ß√µes simples e r√°pidas.
- A **vers√£o Gaussiana** do algoritmo √© adequada quando os atributos cont√≠nuos do conjunto de dados seguem uma distribui√ß√£o normal ‚Äî o que se aplica, em parte, √†s vari√°veis econ√¥micas utilizadas.
- O modelo oferece **alta interpretabilidade**, permitindo an√°lises diretas das probabilidades condicionais e da aplica√ß√£o do Teorema de Bayes na pr√°tica.
- Ferramentas adicionais como `ConfusionMatrix` da biblioteca `yellowbrick` e `classification_report` do `sklearn.metrics` foram utilizadas para **avaliar a performance do classificador**, permitindo visualizar a acur√°cia, precis√£o, recall e F1-score do modelo.
- Tamb√©m foi realizado um **c√°lculo detalhado das probabilidades condicionais**, com base no Teorema de Bayes, refor√ßando a fundamenta√ß√£o matem√°tica da an√°lise.

Essa abordagem demonstrou ser eficaz na identifica√ß√£o de padr√µes nos dados de c√¢mbio e Bitcoin, com acur√°cia superior a 94%, o que refor√ßa sua adequa√ß√£o para problemas de classifica√ß√£o financeira com m√∫ltiplas categorias como *Conservative*, *Crypto-Friendly* e *Neutral*.

## Justificativas das Etapas da Pipeline

A seguir, detalharemos individualmente cada uma das etapas (pipes) que comp√µem a pipeline completa desenvolvida neste trabalho. Cada pipe representa uma transforma√ß√£o ou processo espec√≠fico aplicado aos dados, sendo essencial para garantir a robustez e a coer√™ncia dos resultados finais. As justificativas apresentadas explicam as escolhas metodol√≥gicas, t√©cnicas utilizadas e o papel de cada componente na estrutura geral da solu√ß√£o.

---

### Pipe 1 ‚Äì Importa√ß√£o de Bibliotecas e Montagem de Ambiente

A primeira etapa da pipeline consiste na **importa√ß√£o das bibliotecas** necess√°rias e na **configura√ß√£o do ambiente de trabalho**, garantindo que todos os recursos estejam dispon√≠veis para o restante do processamento e an√°lise dos dados.

#### Instala√ß√£o e Atualiza√ß√£o de Bibliotecas

- O comando `!pip install plotly --upgrade` foi utilizado para garantir que a biblioteca `plotly`, respons√°vel por visualiza√ß√µes interativas, estivesse na vers√£o mais recente, prevenindo incompatibilidades com recursos gr√°ficos utilizados posteriormente.

#### Bibliotecas Importadas

- `requests`: permite o consumo de APIs REST, utilizada para acessar dados da Alpha Vantage.
- `pandas` e `numpy`: essenciais para manipula√ß√£o e an√°lise de dados estruturados.
- `seaborn` e `matplotlib.pyplot`: utilizadas para a cria√ß√£o de gr√°ficos est√°ticos e an√°lise explorat√≥ria dos dados.
- `plotly.express`: biblioteca complementar para cria√ß√£o de gr√°ficos interativos.
- `sklearn.preprocessing`: classes como `StandardScaler`, `LabelEncoder` e `OneHotEncoder` s√£o fundamentais para padroniza√ß√£o e transforma√ß√£o dos dados.
- `ColumnTransformer`: utilizada para aplicar diferentes transforma√ß√µes a colunas distintas em pipelines complexas.
- `train_test_split`: para divis√£o dos dados em conjuntos de treino e teste, essencial na avalia√ß√£o de modelos.
- `pickle`: permite salvar e carregar objetos Python serializados, como datasets e modelos.

#### Instancia√ß√£o de Transformadores

- `StandardScaler` e `LabelEncoder` foram instanciados para uso posterior nas transforma√ß√µes dos dados, visando normaliza√ß√£o e codifica√ß√£o de vari√°veis categ√≥ricas.

#### Montagem do Google Drive

- A linha `drive.mount('/content/drive')` integra o ambiente do Google Colab com o Google Drive do usu√°rio, permitindo acesso direto a arquivos armazenados na nuvem, como bases de dados em `.pkl` e modelos previamente salvos.

Essa etapa √© fundamental para garantir que todas as ferramentas estejam devidamente carregadas e que o ambiente esteja preparado para executar as etapas seguintes da an√°lise.

---

### Pipe 2 ‚Äì Coleta e Convers√£o das Fontes de Dados

Nesta etapa, s√£o realizadas as requisi√ß√µes √† API **Alpha Vantage** para coleta de duas fontes de dados distintas: a varia√ß√£o di√°ria do c√¢mbio **USD/BRL** e os dados hist√≥ricos di√°rios do **Bitcoin em EUR**. Ambas as fontes ser√£o posteriormente ajustadas para refletir apenas os **√∫ltimos 90 dias** na pr√≥xima etapa da pipeline.

#### Coleta da Varia√ß√£o Di√°ria USD/BRL com `FX_DAILY`

Utilizamos a fun√ß√£o `FX_DAILY` da API para acessar a s√©rie temporal de c√¢mbio entre o d√≥lar americano (USD) e o real brasileiro (BRL). A requisi√ß√£o √© feita por meio de uma URL espec√≠fica:

```python
url_fx_currency = 'https://www.alphavantage.co/query?function=FX_DAILY&outputsize=full&from_symbol=USD&to_symbol=BRL&apikey=CHAVE'
```

A resposta em formato JSON √© convertida para um DataFrame do pandas e ordenada cronologicamente pelas datas:

```
r = requests.get(url_fx_currency)
data = r.json()
fx_time_series = data['Time Series FX (Daily)']
fx_df = pd.DataFrame.from_dict(fx_time_series, orient='index')
fx_df.index = pd.to_datetime(fx_df.index)
fx_df = fx_df.sort_index()
```

A op√ß√£o outputsize=full permite obter uma s√©rie hist√≥rica completa, e a filtragem para os √∫ltimos 90 dias ser√° implementada na pr√≥xima pipe, garantindo maior flexibilidade no recorte temporal.

#### Coleta dos Dados de Bitcoin com DIGITAL_CURRENCY_DAILY
A coleta dos dados do Bitcoin √© feita utilizando o endpoint DIGITAL_CURRENCY_DAILY, com foco no par BTC/EUR:

```
url_btc = 'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=EUR&apikey=CHAVE'
```

De forma semelhante √† etapa anterior, a resposta √© transformada em DataFrame com indexa√ß√£o temporal:

```
r = requests.get(url_btc)
data = r.json()
btc_time_series = data['Time Series (Digital Currency Daily)']
btc_df = pd.DataFrame.from_dict(btc_time_series, orient='index')
btc_df.index = pd.to_datetime(btc_df.index)
btc_df = btc_df.sort_index()
```

Essa estrutura permite o acesso direto √†s colunas de pre√ßos de abertura, fechamento, m√°xima, m√≠nima e volume di√°rio em EUR, sendo todos dados √∫teis para an√°lise cruzada com a varia√ß√£o cambial.

#### Alinhamento Temporal e Merge das Duas Fontes

Para permitir an√°lises conjuntas entre o comportamento do Bitcoin e a varia√ß√£o cambial do d√≥lar, as duas bases s√£o unificadas por meio de um merge temporal pelas datas:

```
fx_btc_df = pd.merge(fx_df, btc_df, left_index=True, right_index=True, how='inner')
```

A op√ß√£o how='inner' garante que apenas as datas presentes em ambas as fontes sejam consideradas, o que ajuda a evitar registros incompletos. Cada linha resultante do fx_btc_df representa um dia em que tanto o valor do d√≥lar quanto do Bitcoin estavam dispon√≠veis, permitindo compara√ß√µes e an√°lises correlacionais confi√°veis.

Essa etapa √© fundamental para garantir a qualidade e coer√™ncia temporal dos dados que alimentar√£o os modelos e an√°lises subsequentes, estabelecendo uma base s√≥lida e sincronizada entre as vari√°veis cambiais e criptoecon√¥micas.

---

### Pipe 3 ‚Äì Aplica√ß√£o de Requisitos da Prova

Com as bases de dados cambial e criptoecon√¥mica devidamente integradas e ordenadas, esta etapa tem como objetivo aplicar os requisitos espec√≠ficos propostos na prova, garantindo que o conjunto final de dados esteja pronto para an√°lise conforme o escopo definido.

#### Filtro do DataFrame para os √öltimos 90 Dias

Neste subpipe, √© implementado o recorte temporal dos dados, limitando a amostra aos **√∫ltimos 90 dias** dispon√≠veis. Essa filtragem √© realizada utilizando o m√©todo `tail(90)` do pandas:

```python
fx_btc_df = fx_btc_df.tail(90)
```

Esse comando seleciona as 90 linhas mais recentes do DataFrame, considerando a ordena√ß√£o cronol√≥gica previamente aplicada na etapa de coleta e merge. Essa abordagem garante que os dados mais atuais sejam utilizados nas an√°lises, alinhando-se √† proposta de refletir as din√¢micas recentes do c√¢mbio e da criptoeconomia.

A aplica√ß√£o deste filtro √© essencial para manter a relev√¢ncia temporal da an√°lise e evitar que dados muito antigos distor√ßam os resultados ou a interpreta√ß√£o de tend√™ncias recentes. Com isso, o foco permanece em um horizonte de tempo curto e mais significativo do ponto de vista econ√¥mico e financeiro.

### Renomea√ß√£o dos Atributos para Facilitar a Leitura

Ap√≥s o recorte temporal, os nomes das colunas no DataFrame ainda seguem a nomenclatura original da API da Alpha Vantage, o que pode comprometer a legibilidade e a clareza do conjunto de dados. Assim, realiza-se a renomea√ß√£o dos atributos com identificadores mais intuitivos e padronizados:

```
fx_btc_df = fx_btc_df.rename(columns={
    '1. open_x': 'fx_open',
    '2. high_x': 'fx_high',
    '3. low_x': 'fx_low',
    '4. close_x': 'fx_close',
    '1. open_y': 'btc_open',
    '2. high_y': 'btc_high',
    '3. low_y': 'btc_low',
    '4. close_y': 'btc_close',
    '5. volume': 'btc_volume'
})
```

Essa transforma√ß√£o tem como objetivo melhorar a usabilidade do dataset em an√°lises subsequentes, visualiza√ß√µes e gera√ß√£o de relat√≥rios. A renomea√ß√£o adota o prefixo fx_ para atributos relativos ao c√¢mbio USD/BRL e btc_ para os atributos referentes ao Bitcoin, promovendo uma identifica√ß√£o clara e r√°pida da origem de cada vari√°vel.

A clareza na nomenclatura √© um fator importante para a manuten√ß√£o e compreens√£o do c√≥digo, especialmente em contextos de trabalho colaborativo ou avalia√ß√µes acad√™micas, como √© o caso desta prova.

### Redefini√ß√£o dos Tipos dos Dados

Com os dados j√° filtrados e os nomes das colunas devidamente ajustados, esta subetapa trata da convers√£o dos tipos de dados para formatos num√©ricos adequados √†s an√°lises quantitativas que ser√£o realizadas posteriormente.

Inicialmente, ao importar os dados da API e realizar o *merge*, todas as colunas num√©ricas permanecem como **strings** (tipo `object`), o que pode impedir a execu√ß√£o de opera√ß√µes matem√°ticas, c√°lculos estat√≠sticos e visualiza√ß√µes apropriadas.

A verifica√ß√£o do tipo de dados √© realizada com o comando:

```python
fx_btc_df.info()
```

Que apresenta a seguinte sa√≠da:

```
<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 90 entries, 2024-12-30 to 2025-05-02
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype 
---  ------      --------------  ----- 
 0   fx_open     90 non-null     object
 1   fx_high     90 non-null     object
 2   fx_low      90 non-null     object
 3   fx_close    90 non-null     object
 4   btc_open    90 non-null     object
 5   btc_high    90 non-null     object
 6   btc_low     90 non-null     object
 7   btc_close   90 non-null     object
 8   btc_volume  90 non-null     object
```

Para garantir a correta manipula√ß√£o dessas colunas, realiza-se a convers√£o expl√≠cita para o tipo float, utilizando o m√©todo astype(float):

```
fx_btc_df = fx_btc_df.astype(float)
```

Ap√≥s a convers√£o, uma nova verifica√ß√£o confirma a redefini√ß√£o bem-sucedida dos tipos:

```
fx_btc_df.info()
```

Com a seguinte sa√≠da:

```
<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 90 entries, 2024-12-30 to 2025-05-02
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   fx_open     90 non-null     float64
 1   fx_high     90 non-null     float64
 2   fx_low      90 non-null     float64
 3   fx_close    90 non-null     float64
 4   btc_open    90 non-null     float64
 5   btc_high    90 non-null     float64
 6   btc_low     90 non-null     float64
 7   btc_close   90 non-null     float64
 8   btc_volume  90 non-null     float64
```

Essa etapa √© fundamental para garantir a integridade e funcionalidade do DataFrame em an√°lises, modelagens e visualiza√ß√µes futuras. Trabalhar com tipos num√©ricos permite o uso pleno das bibliotecas do ecossistema Python, al√©m de evitar erros de execu√ß√£o decorrentes de tipos incompat√≠veis.

---

### Pipe 4 - Visualiza√ß√µes

Apesar de a visualiza√ß√£o estar originalmente prevista para a etapa **"14. Avalia√ß√£o do modelo e visualiza√ß√µes: linhas temporais, dispers√£o e heatmaps"**, sua execu√ß√£o foi antecipada nesta pipeline com o objetivo de **compreender melhor a natureza dos dados antes da constru√ß√£o de vari√°veis e do treinamento de modelos preditivos**. Esta decis√£o visa garantir uma abordagem mais informada e eficaz para as transforma√ß√µes e an√°lises subsequentes.

#### Resumo Estat√≠stico e Estrutura dos Dados

- O m√©todo `fx_btc_df.describe()` foi utilizado para gerar **estat√≠sticas descritivas** das colunas num√©ricas, permitindo uma vis√£o inicial de tend√™ncias centrais (m√©dia, mediana), dispers√£o (desvio padr√£o) e poss√≠veis valores discrepantes (m√≠nimos e m√°ximos).
- A inspe√ß√£o com `fx_btc_df.info()` forneceu uma vis√£o da **estrutura e integridade dos dados**, confirmando que n√£o h√° valores nulos e que todas as colunas possuem o tipo `float64`, o que facilita o processamento e normaliza√ß√£o subsequente.

#### Normaliza√ß√£o dos Dados

- A transforma√ß√£o dos dados com `StandardScaler` foi aplicada para **padronizar as vari√°veis** (m√©dia zero e desvio padr√£o um), o que √© uma pr√°tica essencial para algoritmos de modelagem que s√£o sens√≠veis √† escala, al√©m de auxiliar na gera√ß√£o de gr√°ficos compar√°veis entre vari√°veis com magnitudes distintas.
- O DataFrame `fx_btc_normalized_df` resultante foi criado para armazenar os dados normalizados, mantendo os nomes originais das colunas para facilitar a leitura e manipula√ß√£o.

#### Linha Temporal de Fechamento do C√¢mbio e Bitcoin e Volume do Bitcoin

- Foi iniciado o uso da biblioteca `matplotlib.pyplot` para **visualiza√ß√£o temporal das vari√°veis `fx_close`, `btc_close` e `btc_volume`**, ou seja, o **pre√ßo de fechamento do c√¢mbio USD/BRL e Bitcoin e volume do Bitcoin ao longo do tempo**.
- O gr√°fico de linha permite uma primeira percep√ß√£o visual de **tend√™ncias, oscila√ß√µes e poss√≠veis sazonalidades**, servindo como base explorat√≥ria para a cria√ß√£o futura das vari√°veis como `variacao_cambio`, `variacao_btc` e `media_movel_btc`.

Essa abordagem explorat√≥ria precoce foi fundamental para identificar comportamentos relevantes nos dados e apoiar decis√µes mais estrat√©gicas nas transforma√ß√µes que ser√£o realizadas na pr√≥xima etapa da pipeline.

#### Gr√°fico de Linhas ‚Äì S√©rie Temporal do C√¢mbio

```
plt.figure(figsize=(12, 5))
plt.plot(fx_btc_df.index, fx_btc_df['fx_close'], label='Pre√ßo de Fechamento de C√¢mbio USD/BRL', color='blue')
plt.plot(fx_btc_df.index, fx_btc_df['fx_high'], label='Pre√ßo M√°ximo de C√¢mbio USD/BRL', color='green')
plt.plot(fx_btc_df.index, fx_btc_df['fx_low'], label='Pre√ßo M√≠nimo de C√¢mbio USD/BRL', color='red')

plt.xlabel('Data')
plt.ylabel('Pre√ßo de Fechamento')
plt.title('Tend√™ncia do Pre√ßo de Fechamento de C√¢mbio USD/BRL')
plt.legend()
plt.grid()
plt.show()
```

O gr√°fico de linhas mostra a varia√ß√£o di√°ria do c√¢mbio USD/BRL ao longo do tempo.

Exibir os valores de m√°ximo (fx_high), m√≠nimo (fx_low) e fechamento (fx_close) permite identificar:

* Picos de volatilidade

* Per√≠odos de estabilidade ou tend√™ncia

* Comportamentos sazonais ou at√≠picos (outliers visuais)

Essas informa√ß√µes s√£o relevantes para criar vari√°veis derivadas, como varia√ß√£o percentual, amplitude ou m√©dia m√≥vel.

#### Boxplots ‚Äì Distribui√ß√£o das Vari√°veis de C√¢mbio

```
sns.boxplot(x=fx_btc_df['fx_open']);
sns.boxplot(x=fx_btc_df['fx_high']);
sns.boxplot(x=fx_btc_df['fx_low']);
sns.boxplot(x=fx_btc_df['fx_close']);
```

Os boxplots fornecem uma vis√£o clara da distribui√ß√£o estat√≠stica das vari√°veis de c√¢mbio (fx_open, fx_high, fx_low, fx_close).

S√£o √∫teis para:

* Identificar valores discrepantes (outliers)

* Avaliar a assimetria das distribui√ß√µes

* Detectar poss√≠vel necessidade de transforma√ß√£o (como normaliza√ß√£o ou padroniza√ß√£o)

Essa visualiza√ß√£o detalhada dos dados de c√¢mbio refor√ßa a import√¢ncia de entender a variabilidade e dispers√£o dos pre√ßos, o que pode impactar diretamente no desempenho de modelos preditivos, principalmente os sens√≠veis √† escala ou √† presen√ßa de valores extremos.

#### Bitcoin (EUR)

Dando continuidade √† fase de explora√ß√£o visual dos dados, esta etapa foca na vari√°vel de criptoativo **Bitcoin**, cotado em **EUR**. Embora essas visualiza√ß√µes fa√ßam parte da etapa 14 ("Avalia√ß√£o do modelo e visualiza√ß√µes"), elas foram antecipadas para apoiar o **entendimento da natureza e comportamento do ativo**, fundamental para decis√µes de modelagem, normaliza√ß√£o e cria√ß√£o de features.

#### Gr√°fico de Linhas ‚Äì Pre√ßo de Fechamento, M√°ximo e M√≠nimo do Bitcoin

```
plt.figure(figsize=(12, 5))
plt.plot(fx_btc_df.index, fx_btc_df['btc_close'], label='Pre√ßo de Fechamento', color='orange')
plt.plot(fx_btc_df.index, fx_btc_df['btc_high'], label='Pre√ßo M√°ximo', color='green')
plt.plot(fx_btc_df.index, fx_btc_df['btc_low'], label='Pre√ßo M√≠nimo', color='red')

plt.xlabel('Data')
plt.ylabel('Pre√ßo de Fechamento')
plt.title('Tend√™ncia do Pre√ßo de Bitcoin EUR')
plt.legend()
plt.grid()
plt.show()
```

O gr√°fico temporal evidencia a volatilidade di√°ria do Bitcoin.

Exibir os valores de fechamento, m√°ximo e m√≠nimo em conjunto permite observar:

* Oscila√ß√µes abruptas

* Tend√™ncias de alta/baixa

* Eventos at√≠picos (como spikes)

Essa visualiza√ß√£o √© essencial para decis√µes sobre normaliza√ß√£o, redu√ß√£o de vari√¢ncia e detec√ß√£o de outliers.

#### Gr√°fico de Linhas ‚Äì Volume de Transa√ß√µes de Bitcoin

```
plt.figure(figsize=(12, 5))
plt.plot(fx_btc_df.index, fx_btc_df['btc_volume'], label='Volume de Transa√ß√£o', color='green')

plt.xlabel('Data')
plt.ylabel('Pre√ßo de Fechamento')
plt.title('Tend√™ncia do Volume de Transa√ß√£o de Bitcoin EUR')
plt.legend()
plt.grid()
plt.show()
```

O volume de transa√ß√µes √© uma vari√°vel complementar e explicativa relevante.

Flutua√ß√µes no volume podem antecipar movimentos de pre√ßo ou indicar picos de interesse/com√©rcio, √∫teis para modelagem preditiva.

#### Boxplots ‚Äì Distribui√ß√µes Estat√≠sticas das Vari√°veis de Bitcoin

```
sns.boxplot(x=fx_btc_df['btc_open']);
sns.boxplot(x=fx_btc_df['btc_high']);
sns.boxplot(x=fx_btc_df['btc_low']);
sns.boxplot(x=fx_btc_df['btc_close']);
sns.boxplot(x=fx_btc_df['btc_volume']);
```

Os boxplots exp√µem a dispers√£o e presen√ßa de valores extremos nas vari√°veis relacionadas ao Bitcoin.

A vari√°vel btc_volume, por exemplo, tende a apresentar distribui√ß√£o assim√©trica com outliers vis√≠veis, o que pode impactar modelos sens√≠veis √† escala.

Essas visualiza√ß√µes antecipadas fornecem subs√≠dios importantes para pr√©-processamento dos dados e defini√ß√£o de estrat√©gias de engenharia de atributos. A observa√ß√£o cuidadosa das flutua√ß√µes de pre√ßo e volume do Bitcoin contribui diretamente para o desenho de modelos mais robustos, al√©m de facilitar a interpreta√ß√£o dos padr√µes temporais complexos desse ativo digital.

---

### Pipe 5 - Engenharia de Atributos

#### Varia√ß√£o de C√¢mbio USD/BRL

A cria√ß√£o da vari√°vel `fx_variation` tem como finalidade calcular a varia√ß√£o di√°ria do valor de fechamento do c√¢mbio USD/BRL. Esse tipo de vari√°vel √© essencial para an√°lises de s√©ries temporais financeiras, pois permite observar tend√™ncias, flutua√ß√µes e poss√≠veis padr√µes de comportamento do mercado cambial ao longo do tempo.

```
fx_btc_df['fx_variation'] = fx_btc_df['fx_close'].diff().shift(-1)
```

Essa linha de c√≥digo realiza os seguintes passos:

diff(): calcula a diferen√ßa entre o valor de fechamento (fx_close) do dia seguinte e o do dia atual. Isto √©, fx_close(t+1) - fx_close(t).

shift(-1): desloca os resultados para cima uma linha, de modo que a varia√ß√£o entre o dia t e o dia t+1 seja atribu√≠da corretamente √† linha do dia t.

Isso resulta em uma nova coluna fx_variation, que representa a Varia√ß√£o do C√¢mbio USD/BRL, conforme a seguinte f√≥rmula:

fx_variation
ùë°
=
fx_close
ùë°
+
1
‚àí
fx_close
ùë°
fx_variation 
t
‚Äã
 =fx_close 
t+1
‚Äã
 ‚àífx_close 
t

Essa transforma√ß√£o atende ao item 4. C√°lculo das vari√°veis, mais especificamente ao subitem:

Variacao_cambio = fechamento USD/BRL atual - anterior

Contudo, a implementa√ß√£o opta por calcular a varia√ß√£o futura relativa ao ponto atual, o que √© uma abordagem comum em an√°lises preditivas onde o objetivo pode ser, por exemplo, antecipar movimentos de mercado. A inclus√£o dessa vari√°vel no dataset permite que o modelo identifique como mudan√ßas no c√¢mbio se relacionam com outros indicadores, como o pre√ßo do Bitcoin ou o volume de transa√ß√µes.

#### Varia√ß√£o do Bitcoin (EUR)

A cria√ß√£o da vari√°vel `btc_variation` visa calcular a varia√ß√£o di√°ria do pre√ßo de fechamento do Bitcoin (em euros). Essa m√©trica √© crucial para entender os movimentos de mercado do BTC, identificar tend√™ncias de valoriza√ß√£o ou desvaloriza√ß√£o, e correlacionar seu comportamento com outras vari√°veis, como o c√¢mbio USD/BRL.

```
fx_btc_df['btc_variation'] = fx_btc_df['btc_close'].diff().shift(-1)
```

Essa linha realiza duas opera√ß√µes:

diff(): calcula a diferen√ßa entre o valor de fechamento de BTC no dia seguinte e o valor atual. Isto √©, btc_close(t+1) - btc_close(t).

shift(-1): desloca os resultados uma linha para cima, atribuindo corretamente a varia√ß√£o entre os dias t e t+1 √† linha correspondente ao dia t.

Com isso, a coluna btc_variation passa a representar a varia√ß√£o futura no fechamento do Bitcoin com base na seguinte f√≥rmula:

btc_variation t = (btc_close t + 1) ‚àí btc_close t

Essa transforma√ß√£o atende ao requisito especificado no item:

Variacao_btc = fechamento BTC atual - anterior

No entanto, assim como na vari√°vel fx_variation, a escolha de aplicar shift(-1) inverte o c√°lculo tradicional para destacar a varia√ß√£o futura a partir do ponto de vista da data atual. Essa abordagem √© amplamente utilizada em problemas de predi√ß√£o, onde o objetivo √© estimar o que acontecer√° no pr√≥ximo per√≠odo com base nos dados conhecidos hoje.

Essa vari√°vel pode ser particularmente √∫til como vari√°vel alvo (target) ou como indicador de performance de curto prazo em modelos de machine learning voltados para previs√£o de pre√ßos ou an√°lise de risco de investimentos.

#### M√©dia M√≥vel do Bitcoin (EUR)

A cria√ß√£o da vari√°vel `btc_moving_average` tem como objetivo calcular a **m√©dia m√≥vel dos pre√ßos de fechamento do Bitcoin (em EUR)**, considerando os **√∫ltimos 5 dias anteriores** √† data atual. Essa m√©trica suaviza flutua√ß√µes de curto prazo e ajuda a identificar tend√™ncias mais est√°veis no comportamento do ativo ao longo do tempo.

```
fx_btc_df['btc_moving_average'] = fx_btc_df['btc_close'].shift(1).rolling(window=5).mean()
```

Essa linha realiza duas opera√ß√µes fundamentais:

shift(1): desloca os dados de btc_close para que a m√©dia m√≥vel de uma linha seja calculada com base apenas nos dias anteriores, evitando vazamentos de dados futuros (data leakage).

rolling(window=5).mean(): aplica uma janela deslizante de 5 dias e calcula a m√©dia dos valores deslocados, ou seja, a m√©dia dos cinco fechamentos anteriores ao dia corrente.

F√≥rmula
  
i=t‚àí5
‚àë
t‚àí1
‚Äã
 btc_close 
i
‚Äã

Os primeiros cinco valores da m√©dia m√≥vel s√£o NaN, pois n√£o h√° dados suficientes para compor uma janela de cinco dias completos.

Essa transforma√ß√£o atende ao requisito descrito no item:

Media_movel_btc = m√©dia dos √∫ltimos 5 dias do fechamento do BTC

Al√©m disso, o uso da fun√ß√£o shift(1) garante que a m√©dia calculada para o dia t n√£o inclua o valor do pr√≥prio dia, preservando a l√≥gica de um indicador retrospectivo ‚Äî aspecto essencial para aplica√ß√µes em an√°lise de s√©ries temporais, modelos preditivos e estrat√©gias de investimento baseadas em m√©dias m√≥veis (como cruzamento de m√©dias).

#### Tratamento de Valores Faltantes ap√≥s Aplica√ß√£o de Engenharia de Atributos

Ap√≥s a cria√ß√£o de novos atributos derivados no processo de engenharia de atributos, surgiram alguns valores faltantes (NaNs), principalmente nas colunas `fx_variation`, `btc_variation` e `btc_moving_average`. A seguir, descrevemos as estrat√©gias adotadas para lidar com esses valores ausentes, justificando tecnicamente cada decis√£o:

**Preenchimento de `fx_variation` e `btc_variation` com zero**

- **Motiva√ß√£o**: As colunas `fx_variation` e `btc_variation` representam varia√ß√µes de pre√ßo entre dias consecutivos. Como essas colunas s√£o obtidas por meio da diferen√ßa entre valores de fechamento em dias subsequentes, o primeiro valor (ou um valor resultante de uma aus√™ncia anterior) naturalmente se torna nulo.
- **Estrat√©gia adotada**: Preencher com `0` os valores ausentes dessas colunas.
- **Justificativa t√©cnica**:
  - Preencher com a m√©dia ou interpola√ß√£o introduziria vi√©s, especialmente no in√≠cio da s√©rie.
  - Zero representa uma varia√ß√£o neutra, que √© uma escolha segura e coerente quando n√£o h√° dados anteriores dispon√≠veis.
  - Essa abordagem evita distor√ß√µes nos modelos de machine learning, que podem interpretar valores ausentes como informa√ß√µes relevantes.

```
fx_btc_df['fx_variation'] = fx_btc_df['fx_variation'].fillna(0)
fx_btc_df['btc_variation'] = fx_btc_df['btc_variation'].fillna(0)
```

**Preenchimento de `btc_moving_average` com dados reais anteriores ao recorte final**

- **Motiva√ß√£o**: A coluna `btc_moving_average` foi criada como uma m√©dia m√≥vel de 5 dias do pre√ßo de fechamento do BTC, deslocada uma posi√ß√£o no tempo (shift(1)). Naturalmente, os primeiros 4 valores da s√©rie s√£o NaN, pois n√£o h√° dados anteriores suficientes dentro do recorte de 90 dias usado no dataframe final.

- **Estrat√©gia adotada**: Utilizamos dados reais anteriores aos 90 dias finais que foram descartados no recorte final, mas estavam dispon√≠veis por terem sido retornados na requisi√ß√£o original √† API. Esses dados foram utilizados para calcular os primeiros valores de btc_moving_average de maneira leg√≠tima e alinhada com a natureza sequencial da s√©rie temporal.

```
prev_five_fx_btc_df = pd.merge(fx_df, btc_df, left_index=True, right_index=True, how='inner')
prev_five_fx_btc_df = prev_five_fx_btc_df.tail(95)
prev_five_fx_btc_df = prev_five_fx_btc_df.head(10)
prev_five_fx_btc_df['btc_moving_average'] = (
    prev_five_fx_btc_df['4. close_y'].shift(1).rolling(window=5).mean()
)
prev_five_fx_btc_df = prev_five_fx_btc_df.tail(5)
```

- **Justificativa t√©cnica**:
    - Essa abordagem mant√©m a coer√™ncia temporal dos dados e evita imputa√ß√µes artificiais que poderiam comprometer a integridade da s√©rie.

    - O uso de dados reais respeita a cronologia e mant√©m a qualidade do atributo para fins preditivos.

Com essas decis√µes, asseguramos que o dataframe fx_btc_df esteja livre de valores ausentes nas colunas derivadas, sem comprometer a qualidade e a fidelidade dos dados originais. Essa prepara√ß√£o √© essencial para garantir a performance e a confiabilidade dos modelos de aprendizado de m√°quina subsequentes.

#### Defini√ß√£o do Atributo Alvo (Target)

Durante o processo de engenharia de atributos, foi necess√°rio criar a vari√°vel-alvo `scenario`, que representa o cen√°rio econ√¥mico classificado em tr√™s categorias com base nas varia√ß√µes do Bitcoin (BTC) e da taxa de c√¢mbio USD/BRL (FX). A seguir, descrevemos as motiva√ß√µes e justificativas t√©cnicas para a l√≥gica utilizada nessa cria√ß√£o:

**Objetivo da vari√°vel `scenario`**

- Representar o contexto econ√¥mico di√°rio com base nas movimenta√ß√µes do Bitcoin e do d√≥lar.
- Facilitar a classifica√ß√£o de cen√°rios para fins de modelagem preditiva, especialmente com algoritmos probabil√≠sticos como o Naive Bayes.

**Crit√©rios originais sugeridos**

| Varia√ß√£o BTC | Varia√ß√£o C√¢mbio | Classifica√ß√£o      |
|--------------|------------------|--------------------|
| > 0          | > 0              | Crypto-Friendly    |
| > 0          | < 0              | Neutral            |
| < 0          | > 0              | Conservative       |
| < 0          | < 0              | Neutral            |

Essas regras foram elaboradas com base na interpreta√ß√£o econ√¥mica dos movimentos:

- **Crypto-Friendly**: Ambiente favor√°vel para ativos digitais, com valoriza√ß√£o do BTC e alta do d√≥lar (indicando fuga para alternativas).
- **Conservative**: BTC em queda, com d√≥lar valorizando (cen√°rio de avers√£o ao risco e desvaloriza√ß√£o do real).
- **Neutral**: Quando o BTC apresenta pouca varia√ß√£o (lateralizado) ou ambos os ativos se desvalorizam, sugerindo um ambiente neutro ou de menor atratividade para decis√µes estrat√©gicas baseadas em risco.

**Altera√ß√£o t√©cnica implementada**

Na pr√°tica, a varia√ß√£o do BTC pr√≥xima de zero foi considerada uma condi√ß√£o de lateraliza√ß√£o. Para isso, adotou-se o intervalo de ¬±2% como limite de neutralidade. Isso se justifica da seguinte forma:

- **Toler√¢ncia de ¬±2%**: Considera ru√≠do de mercado e volatilidade di√°ria normal. Um movimento inferior a esse intervalo √© considerado lateral, representando aus√™ncia de tend√™ncia definida.

**Implementa√ß√£o em c√≥digo:**

```
def define_scenario(row):
    if abs(row['btc_variation']) <= 0.02 and abs(row['btc_variation']) >= -0.02:
        return 'Neutral'
    elif row['btc_variation'] > 0.02 and row['fx_variation'] > 0:
        return 'Crypto-Friendly'
    elif row['btc_variation'] < 0.02 and row['fx_variation'] > 0:
        return 'Conservative'
    else:
        return 'Neutral'

fx_btc_df['scenario'] = fx_btc_df.apply(define_scenario, axis=1)
```

- **Justificativa t√©cnica da implementa√ß√£o**:

    - Uso de .apply() com axis=1: Necess√°rio para aplicar a l√≥gica linha a linha, pois cada decis√£o depende da combina√ß√£o entre btc_variation e fx_variation.

    - Condi√ß√µes expl√≠citas e prioriza√ß√£o da lateraliza√ß√£o: A primeira verifica√ß√£o garante que valores com baixa oscila√ß√£o no BTC sejam marcados como Neutral antes de qualquer outra l√≥gica ser avaliada.

    - Manuten√ß√£o da consist√™ncia com a interpreta√ß√£o econ√¥mica: Cada cen√°rio representa uma leitura econ√¥mica coerente para auxiliar nos modelos de classifica√ß√£o e decis√µes baseadas em contexto de mercado.

Com isso, o atributo scenario est√° devidamente categorizado e pronto para ser utilizado como vari√°vel-alvo em modelos supervisionados. Ele reflete com fidelidade a conjuntura di√°ria combinada dos mercados de criptoativos e c√¢mbio.

---

### Pipe 6 - Normaliza√ß√£o dos Dados

A etapa de normaliza√ß√£o √© fundamental no pr√©-processamento de dados, especialmente para modelos que utilizam medidas de dist√¢ncia ou distribui√ß√µes estat√≠sticas, como o Naive Bayes. A seguir, detalhamos as subetapas desse processo com suas respectivas justificativas t√©cnicas.

#### Separa√ß√£o de Atributos Preditores e Classe

```
x_fx_btc = fx_btc_df.iloc[:, 9:12].values
x_fx_btc.shape
```

```
y_fx_btc = fx_btc_df.iloc[:, 12].values
y_fx_btc.shape
```

- **Objetivo**: Isolar os atributos preditores (fx_variation, btc_variation, btc_moving_average) da vari√°vel-alvo (scenario) para permitir o treinamento adequado dos modelos.

- **Justificativa t√©cnica**:

    - Separar entrada e sa√≠da √© essencial para qualquer tarefa supervisionada.

    - Garante que a vari√°vel-alvo n√£o interfira na normaliza√ß√£o nem nas etapas subsequentes de modelagem.

    - O uso de .iloc[:, 9:12] √© apropriado, pois os atributos de interesse est√£o posicionados nessas colunas do DataFrame.

#### Padroniza√ß√£o dos Dados

```
x_fx_btc = standardScaler.fit_transform(x_fx_btc)
```

- **Objetivo**: Padronizar os dados (z-score), transformando-os para que tenham m√©dia 0 e desvio padr√£o 1.

- **Justificativa t√©cnica**:

    - Algoritmos como o Naive Bayes podem se beneficiar da padroniza√ß√£o, pois distribui√ß√µes mais pr√≥ximas da normal ajudam a modelagem probabil√≠stica.

    - Melhora a estabilidade num√©rica e evita que vari√°veis com escalas diferentes tenham peso desproporcional na modelagem.

    - Apesar do Naive Bayes ser teoricamente robusto a escala, na pr√°tica, a normaliza√ß√£o contribui para melhor desempenho com dados cont√≠nuos (como vari√¢ncia Gaussiana).

Separa√ß√£o dos Dados de Treinamento e Teste

```
x_fx_btc_train, x_fx_btc_test, y_fx_btc_train, y_fx_btc_test = train_test_split(
    x_fx_btc, y_fx_btc, test_size=0.20, random_state=0
)
```

- **Objetivo**: Dividir os dados em conjuntos de treinamento e teste, garantindo a avalia√ß√£o imparcial do desempenho do modelo.

- **Justificativa t√©cnica**:

    - A separa√ß√£o evita vazamento de informa√ß√£o (data leakage), garantindo que o modelo n√£o "veja" os dados de teste durante o treinamento.

    - O par√¢metro test_size=0.20 define que 20% dos dados ser√£o usados para teste, o que √© adequado para conjuntos pequenos (como os 90 registros do dataframe).

    - O random_state=0 assegura reprodutibilidade dos resultados, importante para fins de valida√ß√£o e compara√ß√£o de desempenho entre diferentes modelos e experimentos.

Com essas etapas, os dados est√£o preparados de maneira apropriada para alimentar algoritmos de aprendizado de m√°quina, garantindo integridade estat√≠stica e coer√™ncia com boas pr√°ticas de pr√©-processamento.

---

### Pipe 7 - Convers√£o e Exporta√ß√£o de Arquivo para Ingest√£o Neural de Dados

```
with open('/content/drive/MyDrive/machine_learning_semestre_5/Pickle/fx_btc.pkl', mode='wb') as f:
  pickle.dump([x_fx_btc_train, x_fx_btc_test, y_fx_btc_train, y_fx_btc_test], f)
```

- **Objetivo**: Persistir os dados pr√©-processados (atributos e classes de treino e teste) em disco para reutiliza√ß√£o em etapas posteriores de modelagem e treinamento, como em redes neurais ou outros algoritmos de machine learning.

- **Justificativa t√©cnica**:

    - Efici√™ncia e modularidade: Ao salvar os dados j√° preparados, evitamos repetir etapas de pr√©-processamento em execu√ß√µes futuras, tornando o pipeline mais eficiente.

    - Padroniza√ß√£o do fluxo de trabalho: A exporta√ß√£o em formato .pkl (via pickle) √© compat√≠vel com diversas bibliotecas de machine learning e deep learning, como Scikit-learn, TensorFlow e PyTorch.

    - Reprodutibilidade: Armazenar os conjuntos de treino e teste com os mesmos dados utilizados na fase de normaliza√ß√£o e split garante que experimentos futuros sejam realizados nas mesmas condi√ß√µes.

    - Organiza√ß√£o: A escolha de um caminho espec√≠fico no Google Drive (/content/drive/...) permite integra√ß√£o direta com o ambiente do Google Colab, facilitando a continuidade do trabalho entre sess√µes e dispositivos.

Com essa abordagem, os dados ficam prontos para serem ingeridos diretamente por arquiteturas neurais ou outros modelos de forma estruturada, r√°pida e confi√°vel.

### Pipe 8 - Importa√ß√£o de Bibliotecas

```
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report
from yellowbrick.classifier import ConfusionMatrix
from collections import Counter
```

- **Objetivo**: Preparar o ambiente com bibliotecas essenciais para constru√ß√£o, avalia√ß√£o e interpreta√ß√£o de um modelo de classifica√ß√£o baseado no algoritmo Naive Bayes.

- **Justificativa t√©cnica**:

    - GaussianNB (Scikit-learn): Implementa o algoritmo Naive Bayes Gaussiano, adequado para vari√°veis cont√≠nuas e normalmente distribu√≠das, como as varia√ß√µes e m√©dias m√≥veis utilizadas nos atributos preditores do modelo.

    - accuracy_score e classification_report (Scikit-learn): Ferramentas fundamentais para mensurar o desempenho do modelo. O accuracy_score fornece a acur√°cia global da classifica√ß√£o, enquanto o classification_report detalha m√©tricas por classe (precis√£o, revoca√ß√£o e F1-score), o que √© crucial para avaliar o desempenho em cen√°rios multiclasses como "Crypto-Friendly", "Neutral" e "Conservative".

    - ConfusionMatrix (Yellowbrick): Permite a visualiza√ß√£o gr√°fica da matriz de confus√£o, facilitando a an√°lise de erros do modelo ao identificar quais classes s√£o mais frequentemente confundidas entre si.

    - Counter (collections): Utilizado para verificar o balanceamento das classes no conjunto de dados, o que pode impactar diretamente o desempenho e a imparcialidade do classificador.

Com essas bibliotecas, o pipeline est√° pronto para construir e interpretar um modelo bayesiano robusto, com suporte a an√°lise estat√≠stica, visualiza√ß√£o de resultados e diagn√≥stico de performance multiclasse.

### Pipe 9 - Carregamento dos Dados para Ingest√£o Neural

```
with open('/content/drive/MyDrive/machine_learning_semestre_5/Pickle/fx_btc.pkl', 'rb') as f:
  x_fx_btc_train, x_fx_btc_test, y_fx_btc_train, y_fx_btc_test = pickle.load(f)
```

- **Objetivo**: Realizar o carregamento dos dados previamente normalizados e particionados em treino e teste, a partir de um arquivo .pkl, para uso direto em modelos de aprendizado de m√°quina ou redes neurais.

- **Justificativa t√©cnica**:

    - Continuidade do pipeline: Essa etapa permite retomar o fluxo de trabalho a partir de onde foi interrompido, utilizando exatamente os mesmos dados pr√©-processados, garantindo consist√™ncia entre sess√µes de modelagem.

    - Reprodutibilidade: Ao utilizar os mesmos dados carregados de forma padronizada, assegura-se que os resultados obtidos em testes e treinamentos sejam reproduz√≠veis, sem varia√ß√µes causadas por pr√©-processamentos repetidos ou aleat√≥rios.

    - Efici√™ncia operacional: O uso do pickle.load() reduz o tempo de prepara√ß√£o ao evitar que as etapas de transforma√ß√£o, normaliza√ß√£o e divis√£o dos dados sejam reexecutadas, economizando recursos computacionais e tempo.

    - Integra√ß√£o com Google Drive: O caminho definido em /content/drive/... garante que o arquivo carregado esteja dispon√≠vel no ambiente do Google Colab, promovendo portabilidade e facilidade de acesso entre diferentes dispositivos ou sess√µes.

Dessa forma, os dados ficam prontos para serem utilizados de maneira r√°pida, segura e estruturada em qualquer modelo de aprendizado supervisionado, incluindo redes neurais.

### Pipe 10 - Ingest√£o Neural e Testagem de Neur√¥nio Artificial GaussianNB

```
gnb_fx_btc = GaussianNB()
gnb_fx_btc.fit(x_fx_btc_train, y_fx_btc_train)

gnb_fx_btc_predict = gnb_fx_btc.predict(x_fx_btc_test)
```

- **Objetivo**: Realizar o treinamento de um modelo de classifica√ß√£o baseado no algoritmo Naive Bayes Gaussiano (GaussianNB), utilizando os dados previamente normalizados e divididos em treino e teste. A seguir, gerar as previs√µes a partir do modelo treinado sobre os dados de teste.

- **Justificativa t√©cnica**:

    - Algoritmo probabil√≠stico robusto: O GaussianNB √© uma varia√ß√£o do algoritmo Naive Bayes, que assume que os atributos seguem uma distribui√ß√£o normal. Ele √© eficaz para tarefas de classifica√ß√£o com conjuntos de dados cont√≠nuos e √© particularmente √∫til em problemas com alta dimensionalidade e independ√™ncia entre atributos.

    - Velocidade de treinamento: O GaussianNB √© extremamente r√°pido tanto no treinamento quanto na predi√ß√£o, sendo adequado para an√°lises preliminares, valida√ß√µes cruzadas e testes de hip√≥teses sobre a capacidade discriminativa dos dados.

    - Baixa complexidade computacional: Por n√£o exigir hiperpar√¢metros complexos ou redes neurais profundas, o modelo pode ser treinado mesmo em ambientes com limita√ß√µes computacionais, como o Google Colab gratuito.

    - Aplicabilidade √† ingest√£o neural: Embora o GaussianNB n√£o seja um neur√¥nio artificial no sentido das redes neurais profundas, ele simula um comportamento de classificador neural b√°sico, sendo uma excelente etapa inicial de teste antes de partir para arquiteturas mais sofisticadas, como MLPs ou CNNs.

    - Compatibilidade com frameworks de avalia√ß√£o: O resultado da predi√ß√£o (gnb_fx_btc_predict) pode ser utilizado com m√©tricas de avalia√ß√£o como accuracy, classification report e confusion matrix, fornecendo uma base clara para compara√ß√£o com modelos mais complexos.

Assim, essa pipe implementa de forma eficaz o requisito de Treinamento com GaussianNB, servindo como ponto de partida confi√°vel e interpret√°vel para an√°lises de desempenho em classificadores supervisionados.

### Pipe 11 - Avalia√ß√£o do Modelo  

```
gnb_fx_btc_accuracy = accuracy_score(y_fx_btc_test, gnb_fx_btc_predict)
print('P(A) = ' + str(round((gnb_fx_btc_accuracy * 100), 2)) + '%')
```

#### C√°lculo probabil√≠stico com Teorema de Bayes

```
classes = np.unique(np.concatenate((y_fx_btc_test, gnb_fx_btc_predict)))
bayes_results = {}
for cls in classes:
    p_b = np.sum(gnb_fx_btc_predict == cls) / len(gnb_fx_btc_predict)
    p_a = np.sum(y_fx_btc_test == cls) / len(y_fx_btc_test)
    mask = y_fx_btc_test == cls
    p_b_a = np.sum(gnb_fx_btc_predict[mask] == cls) / np.sum(mask) if np.sum(mask) > 0 else 0
    p_a_b = (p_b_a * p_a) / p_b if p_b > 0 else 0
    bayes_results[cls] = {
        'P(A)': round(p_a, 3),
        'P(B)': round(p_b, 3),
        'P(B|A)': round(p_b_a, 3),
        'P(A|B)': round(p_a_b, 3)
    }
bayes_df = pd.DataFrame(bayes_results).T
print(bayes_df)
```

#### Matriz de confus√£o

```
gnb_fx_btc_cm = ConfusionMatrix(gnb_fx_btc)
gnb_fx_btc_cm.fit(x_fx_btc_train, y_fx_btc_train)
gnb_fx_btc_cm.score(x_fx_btc_test, y_fx_btc_test)
```

#### Relat√≥rio de Classifica√ß√£o

```
print(classification_report(y_fx_btc_test, gnb_fx_btc_predict))
```

- **Objetivo**: Avaliar o desempenho do classificador GaussianNB a partir de m√©tricas quantitativas e qualitativas, utilizando medidas estat√≠sticas como accuracy, matriz de confus√£o, relat√≥rio de classifica√ß√£o e o Teorema de Bayes para an√°lise probabil√≠stica dos resultados.

- **Justificativa t√©cnica**:

    - Precis√£o geral (Accuracy): A m√©trica accuracy_score fornece uma vis√£o direta da taxa de acerto do modelo em rela√ß√£o ao total de amostras de teste, sendo uma medida base para valida√ß√£o de classificadores.

    - Probabilidade condicional via Teorema de Bayes: O c√°lculo das probabilidades ùëÉ(ùê¥), ùëÉ(ùêµ), ùëÉ(ùêµ‚à£ùê¥) e ùëÉ(ùê¥‚à£ùêµ) permite avaliar a coer√™ncia das predi√ß√µes do modelo sob uma √≥tica estat√≠stica, fornecendo insights sobre o comportamento das classes previstas em rela√ß√£o √†s classes reais.

    - Interpreta√ß√£o qualitativa com matriz de confus√£o: A visualiza√ß√£o das predi√ß√µes corretas e incorretas para cada classe permite detectar tend√™ncias de erro, como confus√µes recorrentes entre categorias semelhantes.

    - Relat√≥rio de desempenho detalhado: O classification_report agrega informa√ß√µes sobre precis√£o (precision), revoca√ß√£o (recall) e f1-score, possibilitando uma an√°lise equilibrada do modelo em contextos de classes desbalanceadas.

    - Valida√ß√£o visual e interpret√°vel: A matriz de confus√£o gerada com Yellowbrick fornece uma interface gr√°fica que auxilia na interpreta√ß√£o r√°pida e intuitiva dos resultados, mesmo por usu√°rios n√£o especialistas.

Essa pipe implementa com rigor o requisito 14 - Avalia√ß√£o do Modelo, entregando um conjunto completo de m√©tricas fundamentais para a an√°lise de classificadores supervisionados, baseando-se em boas pr√°ticas estat√≠sticas e de machine learning.